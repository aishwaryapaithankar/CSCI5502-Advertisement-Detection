{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhAB_Gv46rHy"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!unzip \"drive/My Drive/train.zip\"\n",
        "!unzip \"drive/My Drive/val.zip\""
      ],
      "id": "KhAB_Gv46rHy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "515ad077"
      },
      "outputs": [],
      "source": [
        "import keras,os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "\n",
        "# base_dir = '/root/Project'\n",
        "\n",
        "# train_dir = os.path.join(base_dir, 'train')\n",
        "# validation_dir = os.path.join(base_dir, 'val')\n",
        "# test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "train_dir = 'train'\n",
        "validation_dir = 'val'\n",
        "test_dir = 'test'\n",
        "\n",
        "# Directory with our training ad pictures\n",
        "train_ads_dir = os.path.join(train_dir, 'pos')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_noads_dir = os.path.join(train_dir, 'neg')\n",
        "\n",
        "# Directory with our validation ad pictures\n",
        "validation_ads_dir = os.path.join(validation_dir, 'pos')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_noads_dir = os.path.join(validation_dir, 'neg')\n"
      ],
      "id": "515ad077"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "def64ee0"
      },
      "outputs": [],
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )"
      ],
      "id": "def64ee0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e052df7",
        "outputId": "eae2ab4b-fd62-4bbd-8a2f-1dae74caf5f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 47057 images belonging to 2 classes.\n",
            "Found 15685 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, batch_size = 20, class_mode = 'binary', target_size = (300, 300))\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator = test_datagen.flow_from_directory( validation_dir,  batch_size = 20, class_mode = 'binary', target_size = (300, 300))"
      ],
      "id": "4e052df7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "623d4637"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten , Dropout\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "base_model = VGG16(input_shape = (300, 300, 3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "# Flatten the output layer to 1 dimension\n",
        "x = Flatten()(base_model.output)\n",
        "\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "x = Dense(512, activation='relu')(x)\n",
        "\n",
        "# Add a dropout rate of 0.5\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Add a final sigmoid layer with 1 node for classification output\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = keras.models.Model(base_model.input, x)\n",
        "\n",
        "model.compile(optimizer = keras.optimizers.Adam(learning_rate=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])"
      ],
      "id": "623d4637"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "532a913d"
      },
      "outputs": [],
      "source": [
        "vgghist = model.fit(train_generator, validation_data = validation_generator, steps_per_epoch = 100, epochs = 10)"
      ],
      "id": "532a913d"
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"drive/My Drive/test.zip\""
      ],
      "metadata": {
        "id": "RtoeunApKWg7"
      },
      "id": "RtoeunApKWg7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f22dcdd0"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Save model\n",
        "model.save(\"Ad_NoAd_VGG.h5\")"
      ],
      "id": "f22dcdd0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d19611ce"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from PIL import Image\n",
        "\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "# Flow test images in batches of 20 using test_datagen generator\n",
        "test_gen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "test_generator = test_gen.flow_from_directory( test_dir,  batch_size = 20, class_mode = 'binary', target_size = (300, 300))\n",
        "saved_model = load_model(\"Ad_NoAd_VGG.h5\")\n",
        "\n",
        "# Evaluate on test data\n",
        "scores = saved_model.evaluate(test_generator)\n",
        "print(\"%s%s: %.2f%%\" % (\"evaluate \",saved_model.metrics_names[1], scores[1]*100))"
      ],
      "id": "d19611ce"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# y_pred = saved_model.predict(test_generator)\n",
        "y_pred = saved_model.predict(test_generator)"
      ],
      "metadata": {
        "id": "d1dn1XP1sE1l"
      },
      "id": "d1dn1XP1sE1l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.rint(y_pred)\n",
        "print(confusion_matrix(test_generator.classes, y_pred))\n",
        "tn, fp, fn, tp = confusion_matrix(test_generator.classes, y_pred).ravel()\n",
        "print(tn, fp, fn, tp)"
      ],
      "metadata": {
        "id": "aBWQtq-G5M12"
      },
      "id": "aBWQtq-G5M12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(test_generator.classes, y_pred))"
      ],
      "metadata": {
        "id": "LVuhgci7-bvN"
      },
      "id": "LVuhgci7-bvN",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}